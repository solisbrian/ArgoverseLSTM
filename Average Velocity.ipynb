{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a99460d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "from torch.autograd import Variable\n",
    "from statistics import mean\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "train_path = \"./new_train/\"\n",
    "val_path = \"./new_val_in/\"\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0832aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset  = ArgoverseDataset(data_path=train_path)\n",
    "val_dataset =  ArgoverseDataset(data_path=val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cc925ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 32\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    #a_id =[numpy.dstack([scene['agent_id']]) for scene in batch]\n",
    "    #t_id =[numpy.dstack([scene['track_id']]) for scene in batch]\n",
    "    #inp = torch.LongTensor(inp)\n",
    "    #out = torch.LongTensor(out)\n",
    "    inp =  torch.FloatTensor(inp)\n",
    "    out =  torch.FloatTensor(out)\n",
    "    \n",
    "    return [inp, out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea1504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 32\n",
    "\n",
    "def my_collate2(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    #out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "    a_id =[numpy.dstack([scene['agent_id']]) for scene in batch]\n",
    "    t_id =[numpy.dstack([scene['track_id']]) for scene in batch]\n",
    "    s_id =[numpy.dstack([scene['scene_idx']]) for scene in batch] \n",
    "    #inp = torch.LongTensor(inp)\n",
    "    #out = torch.LongTensor(out)\n",
    "    inp =  torch.FloatTensor(inp)\n",
    "    #out =  torch.FloatTensor(out)\n",
    "    \n",
    "    return [inp,a_id,t_id,s_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b147bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = True, collate_fn=my_collate, num_workers=1)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate2, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab4001ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 19, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = train_dataset.__getitem__(0)['v_in']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ba830d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3277.29638672, 1947.62585449])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene = train_dataset.__getitem__(0)\n",
    "scene['p_in'][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1d4b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_agent(scene):\n",
    "    agent_id = scene['agent_id']\n",
    "    for i in range(60):\n",
    "        track_id = scene['track_id'][i][0]\n",
    "        if(agent_id == track_id):\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e5be322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_agent_velocity(scene):\n",
    "    v_all = scene['v_in']\n",
    "    agent_idx = find_agent(scene)\n",
    "    v_agent = v_all[agent_idx]\n",
    "    vx = mean(v_agent[:, 0][14:18])\n",
    "    vy = mean(v_agent[:, 1][14:18])\n",
    "    return vx, vy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa838869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.396494448184967, 2.59128400683403)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_agent_velocity(train_dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f6ae1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vx_all = []\n",
    "vy_all = []\n",
    "for i in range(val_dataset.__len__()):\n",
    "    scene = val_dataset.__getitem__(i)\n",
    "    vx, vy =avg_agent_velocity(scene)\n",
    "    vx_all.append(vx)\n",
    "    vy_all.append(vy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe5374af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vx_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "69386755",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in range(val_dataset.__len__()):\n",
    "    agent_output = []\n",
    "    scene = val_dataset.__getitem__(i)\n",
    "    agent_idx = find_agent(scene)\n",
    "    start_px = val_dataset.__getitem__(i)['p_in'][agent_idx][-1][0]\n",
    "    start_py = val_dataset.__getitem__(i)['p_in'][agent_idx][-1][1]\n",
    "    vx, vy = avg_agent_velocity(scene)\n",
    "    for j in range(1,31):\n",
    "        px = start_px  + vx*0.1*j\n",
    "        py = start_py + vy*0.1*j\n",
    "        agent_output.append(px)\n",
    "        agent_output.append(py)\n",
    "    output.append(agent_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9dd2ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = [\"v1\", \"v2\", \"v3\", \"v4\", \"v5\", \"v6\", \"v7\", \"v8\", \"v9\", \"v10\", \"v11\", \"v12\", \"v13\", \"v14\", \"v15\", \"v16\", \"v17\", \"v18\", \"v19\", \"v20\", \"v21\", \"v22\", \"v23\", \"v24\", \"v25\", \"v26\", \"v27\", \"v28\", \"v29\", \"v30\", \"v31\", \"v32\", \"v33\", \"v34\", \"v35\", \"v36\", \"v37\", \"v38\", \"v39\", \"v40\", \"v41\", \"v42\", \"v43\", \"v44\", \"v45\", \"v46\", \"v47\", \"v48\", \"v49\", \"v50\", \"v51\", \"v52\", \"v53\", \"v54\", \"v55\", \"v56\", \"v57\", \"v58\", \"v59\", \"v60\"]\n",
    "output = numpy.array(output)\n",
    "# var = numpy.stack((y, final))\n",
    "numpy.savetxt(\"submission_avg3.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f07e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
